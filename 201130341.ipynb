{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scipy \n",
    "# Used for the checksum in the dataset download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision.datasets import Flowers102\n",
    "from torch.utils.data import Subset, ConcatDataset\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking what device is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Torch:\", torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT: str = \"./data\" \n",
    "TRAIN_RELATIVE_SIZE: float = 0.5\n",
    "VALIDATION_RELATIVE_SIZE: float = 0.25\n",
    "TEST_RELATIVE_SIZE: float = 0.25\n",
    "YOLOV5_MODEL = 'yolov5s'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire dataset to be processed later.\n",
    "full_dataset = torch.utils.data.ConcatDataset([\n",
    "    Flowers102(root=DATASET_ROOT, split=\"train\", download=True),\n",
    "    Flowers102(root=DATASET_ROOT, split=\"val\",   download=True),\n",
    "    Flowers102(root=DATASET_ROOT, split=\"test\",  download=True),\n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 8189\n",
      "Classes: 102\n",
      "Min per class: 40\n",
      "Max per class: 258\n",
      "Imbalance ratio (max/min): 6.45\n"
     ]
    }
   ],
   "source": [
    "labels = np.asarray(full_dataset._labels, dtype=int)\n",
    "counts = Counter(labels)\n",
    "\n",
    "num_classes = len(counts)\n",
    "total = len(labels)\n",
    "min_c = min(counts.values())\n",
    "max_c = max(counts.values())\n",
    "\n",
    "print(f\"Total samples: {total}\")\n",
    "print(f\"Classes: {num_classes}\")\n",
    "print(f\"Min per class: {min_c}\")\n",
    "print(f\"Max per class: {max_c}\")\n",
    "print(f\"Imbalance ratio (max/min): {max_c/min_c:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added utility functions to properly separate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_labels_from_concat_dataset(concat_dataset: ConcatDataset):\n",
    "    \"\"\"Collect labels from each underlying dataset without loading images.\"\"\"\n",
    "    all_labels_list = []\n",
    "\n",
    "    for single_dataset in concat_dataset.datasets:\n",
    "        if hasattr(single_dataset, \"_labels\"):          # Flowers102\n",
    "            labels_array = np.asarray(single_dataset._labels, dtype=int)\n",
    "        elif hasattr(single_dataset, \"targets\"):        # ImageFolder, CIFAR, etc.\n",
    "            labels_array = np.asarray(single_dataset.targets, dtype=int)\n",
    "        else:  # fallback (slow)\n",
    "            labels_array = np.array(\n",
    "                [single_dataset[i][1] for i in range(len(single_dataset))],\n",
    "                dtype=int\n",
    "            )\n",
    "\n",
    "        all_labels_list.append(labels_array)\n",
    "\n",
    "    return np.concatenate(all_labels_list)\n",
    "\n",
    "\n",
    "def stratified_split_concat_dataset(\n",
    "    concat_dataset: ConcatDataset,\n",
    "    split_fractions=(0.8, 0.1, 0.1),\n",
    "    random_seed=42\n",
    "):\n",
    "    \"\"\"Split ConcatDataset into stratified Subsets with same class proportions.\"\"\"\n",
    "\n",
    "    normalized_fractions = np.array(split_fractions, dtype=float)\n",
    "    normalized_fractions = normalized_fractions / normalized_fractions.sum()\n",
    "\n",
    "    all_labels = extract_all_labels_from_concat_dataset(concat_dataset)\n",
    "    random_generator = np.random.default_rng(random_seed)\n",
    "\n",
    "    # group global indices by class\n",
    "    class_to_indices = defaultdict(list)\n",
    "    for global_index, class_label in enumerate(all_labels):\n",
    "        class_to_indices[int(class_label)].append(global_index)\n",
    "\n",
    "    split_indices_per_subset = [[] for _ in range(len(normalized_fractions))]\n",
    "\n",
    "    for class_indices in class_to_indices.values():\n",
    "        class_indices = np.array(class_indices, dtype=int)\n",
    "        random_generator.shuffle(class_indices)\n",
    "\n",
    "        total_class_samples = len(class_indices)\n",
    "        samples_per_split = np.floor(normalized_fractions * total_class_samples).astype(int)\n",
    "\n",
    "        # distribute leftover samples\n",
    "        remainder = total_class_samples - samples_per_split.sum()\n",
    "        for split_id in random_generator.permutation(len(samples_per_split))[:remainder]:\n",
    "            samples_per_split[split_id] += 1\n",
    "\n",
    "        start_pointer = 0\n",
    "        for split_id, count in enumerate(samples_per_split):\n",
    "            split_indices_per_subset[split_id].extend(\n",
    "                class_indices[start_pointer:start_pointer + count].tolist()\n",
    "            )\n",
    "            start_pointer += count\n",
    "\n",
    "    # shuffle each split's indices\n",
    "    for split_list in split_indices_per_subset:\n",
    "        random_generator.shuffle(split_list)\n",
    "\n",
    "    train_subset, val_subset, test_subset = [\n",
    "        Subset(concat_dataset, indices) for indices in split_indices_per_subset\n",
    "    ]\n",
    "\n",
    "    return train_subset, val_subset, test_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training YoloV5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load(\"ultralytics/yolov5\", YOLOV5_MODEL, pretrained=True)\n",
    "model = model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMEMBER TO DO MULTIPLE SPLITS HONEY\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=666x500>, 19)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"REMEMBER TO DO MULTIPLE SPLITS HONEY\")\n",
    "train_dataset, val_dataset, test_dataset = stratified_split_concat_dataset(\n",
    "    full_dataset,\n",
    "    split_fractions=(TRAIN_RELATIVE_SIZE, VALIDATION_RELATIVE_SIZE, TEST_RELATIVE_SIZE),\n",
    "    random_seed=42\n",
    ")\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation functions\n",
      "Model evaluation functions\n",
      "Model evaluation functions\n",
      "Model evaluation functions\n",
      "Model evaluation functions\n",
      "Model evaluation functions\n",
      "Model evaluation functions\n",
      "Model evaluation functions\n",
      "Model evaluation functions\n",
      "Model evaluation functions\n",
      "Model evaluation functions\n"
     ]
    }
   ],
   "source": [
    "print('Model evaluation functions')\n",
    "print('Model evaluation functions')\n",
    "print('Model evaluation functions')\n",
    "print('Model evaluation functions')\n",
    "print('Model evaluation functions')\n",
    "print('Model evaluation functions')\n",
    "print('Model evaluation functions')\n",
    "print('Model evaluation functions')\n",
    "print('Model evaluation functions')\n",
    "print('Model evaluation functions')\n",
    "print('Model evaluation functions')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
