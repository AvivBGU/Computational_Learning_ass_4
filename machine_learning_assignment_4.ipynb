{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "from torchvision.datasets import Flowers102\n",
    "from torch.utils.data import Subset, ConcatDataset\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "from torchvision import transforms\n",
    "from typing import Tuple, Dict, Optional, Callable\n",
    "import copy\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking what device is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Torch:\", torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "torch.backends.cudnn.benchmark = True # Accelerating training for fixed input size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT: str = \"./data\" \n",
    "TRAIN_RELATIVE_SIZE: float = 0.5\n",
    "VALIDATION_RELATIVE_SIZE: float = 0.25\n",
    "TEST_RELATIVE_SIZE: float = 0.25\n",
    "YOLOV5_MODEL: str = 'yolov5s'\n",
    "DATA_SPLIT_SEED_LIST: list[int] = [42, 43, 44]\n",
    "EXPECTED_IMAGE_SIZE_YOLO: tuple[int, int] = (224, 224)\n",
    "IMAGENET_STD: list[float] = [0.229, 0.224, 0.225]\n",
    "IMAGENET_MEAN: list[float] = [0.485, 0.456, 0.406]\n",
    "PATIENCE_EPOCHS: int = 10\n",
    "IMPROVEMENT_DELTA: float = 0.01\n",
    "MAX_EPOCHS: int = 100\n",
    "BATCH_SIZE: int = 32\n",
    "NUM_WORKERS_FOR_DATALOADER: int = 0  # Set to 0 for Windows compatibility\n",
    "FRESH_LOCAL_VGG_WEIGHTS: str = \"vgg19_fresh.pt\"  # Path to save fresh weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire dataset to be processed later.\n",
    "full_dataset = torch.utils.data.ConcatDataset([\n",
    "    Flowers102(root=DATASET_ROOT, split=\"train\", download=True),\n",
    "    Flowers102(root=DATASET_ROOT, split=\"val\",   download=True),\n",
    "    Flowers102(root=DATASET_ROOT, split=\"test\",  download=True),\n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "\n",
    "for single_dataset in full_dataset.datasets:  # full_dataset is ConcatDataset\n",
    "    all_labels.extend(single_dataset._labels)  # Flowers102 stores labels here\n",
    "counts = Counter(all_labels)\n",
    "\n",
    "num_classes = len(counts)\n",
    "total = len(all_labels)\n",
    "min_c = min(counts.values())\n",
    "max_c = max(counts.values())\n",
    "\n",
    "print(f\"Total samples: {total}\")\n",
    "print(f\"Classes: {num_classes}\")\n",
    "print(f\"Min per class: {min_c}\")\n",
    "print(f\"Max per class: {max_c}\")\n",
    "print(f\"Imbalance ratio (max/min): {max_c/min_c:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added utility functions to properly separate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_labels_from_concat_dataset(concat_dataset: ConcatDataset):\n",
    "    \"\"\"Collect labels from each underlying dataset without loading images.\"\"\"\n",
    "    all_labels_list = []\n",
    "\n",
    "    for single_dataset in concat_dataset.datasets:\n",
    "        if hasattr(single_dataset, \"_labels\"):          # Flowers102\n",
    "            labels_array = np.asarray(single_dataset._labels, dtype=int)\n",
    "        elif hasattr(single_dataset, \"targets\"):        # ImageFolder, CIFAR, etc.\n",
    "            labels_array = np.asarray(single_dataset.targets, dtype=int)\n",
    "        else:  # fallback (slow)\n",
    "            labels_array = np.array(\n",
    "                [single_dataset[i][1] for i in range(len(single_dataset))],\n",
    "                dtype=int\n",
    "            )\n",
    "\n",
    "        all_labels_list.append(labels_array)\n",
    "\n",
    "    return np.concatenate(all_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split_concat_dataset(\n",
    "    concat_dataset: ConcatDataset,\n",
    "    split_fractions=(TRAIN_RELATIVE_SIZE, VALIDATION_RELATIVE_SIZE, TEST_RELATIVE_SIZE),\n",
    "    random_seed=42\n",
    "):\n",
    "    \"\"\"Split ConcatDataset into stratified Subsets with same class proportions.\"\"\"\n",
    "\n",
    "    normalized_fractions = np.array(split_fractions, dtype=float)\n",
    "    normalized_fractions = normalized_fractions / normalized_fractions.sum()\n",
    "\n",
    "    all_labels = extract_all_labels_from_concat_dataset(concat_dataset)\n",
    "    random_generator = np.random.default_rng(random_seed)\n",
    "\n",
    "    # group global indices by class\n",
    "    class_to_indices = defaultdict(list)\n",
    "    for global_index, class_label in enumerate(all_labels):\n",
    "        class_to_indices[int(class_label)].append(global_index)\n",
    "\n",
    "    split_indices_per_subset = [[] for _ in range(len(normalized_fractions))]\n",
    "\n",
    "    for class_indices in class_to_indices.values():\n",
    "        class_indices = np.array(class_indices, dtype=int)\n",
    "        random_generator.shuffle(class_indices)\n",
    "\n",
    "        total_class_samples = len(class_indices)\n",
    "        samples_per_split = np.floor(normalized_fractions * total_class_samples).astype(int)\n",
    "\n",
    "        # distribute leftover samples\n",
    "        remainder = total_class_samples - samples_per_split.sum()\n",
    "        for split_id in random_generator.permutation(len(samples_per_split))[:remainder]:\n",
    "            samples_per_split[split_id] += 1\n",
    "\n",
    "        start_pointer = 0\n",
    "        for split_id, count in enumerate(samples_per_split):\n",
    "            split_indices_per_subset[split_id].extend(\n",
    "                class_indices[start_pointer:start_pointer + count].tolist()\n",
    "            )\n",
    "            start_pointer += count\n",
    "\n",
    "    # shuffle each split's indices\n",
    "    for split_list in split_indices_per_subset:\n",
    "        random_generator.shuffle(split_list)\n",
    "\n",
    "    train_subset, val_subset, test_subset = [\n",
    "        Subset(concat_dataset, indices) for indices in split_indices_per_subset\n",
    "    ]\n",
    "\n",
    "    return train_subset, val_subset, test_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augemntation and requried transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(EXPECTED_IMAGE_SIZE_YOLO, scale=(0.8, 1.0)),  # random crop\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # Random horizontal flip\n",
    "    transforms.RandomAffine( # small random rotations, translations, scaling\n",
    "        degrees=10, \n",
    "        translate=(0.03, 0.03),  \n",
    "        scale=(0.97, 1.03)       \n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN,\n",
    "                         IMAGENET_STD),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A transformation that will be used for testing, just resizing and normalizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize(EXPECTED_IMAGE_SIZE_YOLO),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN,\n",
    "                         IMAGENET_STD),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database to properly handle transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowersDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wrap your existing dataset that returns:\n",
    "      - image: PIL.Image\n",
    "      - label: int (0..num_classes-1)\n",
    "    \"\"\"\n",
    "    def __init__(self, base_dataset: Dataset, transform):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_pil, label = self.base_dataset[idx]\n",
    "        image_pil = self.transform(image_pil)\n",
    "        return image_pil, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data while preseving ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_splits(\n",
    "    full_dataset: ConcatDataset,\n",
    "    random_seed: int,\n",
    "    transform_for_train: Optional[Callable],\n",
    "    transform_for_val_test: Optional[Callable]\n",
    ") -> Tuple[Dataset, Dataset, Dataset]:\n",
    "    train_subset, val_subset, test_subset = stratified_split_concat_dataset(\n",
    "        concat_dataset=full_dataset,\n",
    "        random_seed=random_seed\n",
    "    )\n",
    "    train_dataset = FlowersDataset(train_subset, transform=transform_for_train)\n",
    "    val_dataset = FlowersDataset(val_subset, transform=transform_for_val_test)\n",
    "    test_dataset = FlowersDataset(test_subset, transform=transform_for_val_test)\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataloaders    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(\n",
    "    train_dataset: Dataset,\n",
    "    val_dataset: Dataset,\n",
    "    test_dataset: Dataset,\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "    num_workers: int = NUM_WORKERS_FOR_DATALOADER\n",
    ") -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early stopping logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience_epochs: int = PATIENCE_EPOCHS, min_delta: float = IMPROVEMENT_DELTA):\n",
    "        self.patience_epochs = patience_epochs\n",
    "        self.min_delta = min_delta\n",
    "        self.best_value: Optional[float] = None\n",
    "        self.epochs_without_improvement: int = 0\n",
    "        self.best_state_dict: Optional[Dict[str, torch.Tensor]] = None\n",
    "\n",
    "    def step(self, current_value: float, model: nn.Module) -> tuple[bool, bool]:\n",
    "        \"\"\"\n",
    "        Returns should_stop, improved\n",
    "        \"\"\"\n",
    "        if self.best_value is None: # Only relevant in the first call\n",
    "            self.best_value = current_value\n",
    "            self.best_state_dict = copy.deepcopy(model.state_dict())\n",
    "            return False, True\n",
    "\n",
    "        improved = current_value < (self.best_value - self.min_delta)\n",
    "\n",
    "        if improved:\n",
    "            self.best_value = current_value\n",
    "            self.epochs_without_improvement = 0\n",
    "            self.best_state_dict = copy.deepcopy(model.state_dict())\n",
    "            return False, True\n",
    "\n",
    "        self.epochs_without_improvement += 1\n",
    "        should_stop = self.epochs_without_improvement >= self.patience_epochs\n",
    "        return should_stop, improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running single training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_epoch_train(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    loss_function: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float]:\n",
    "    model.train()\n",
    "\n",
    "    total_loss_value = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch_images, batch_targets in train_dataloader:\n",
    "        batch_images = batch_images.to(device, non_blocking=True)\n",
    "        batch_targets = batch_targets.to(device, non_blocking=True).long()\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        batch_logits = model(batch_images)\n",
    "        # If your model returns a tuple/dict, adapt here:\n",
    "        if isinstance(batch_logits, (tuple, list)):\n",
    "            batch_logits = batch_logits[0]\n",
    "\n",
    "        batch_loss = loss_function(batch_logits, batch_targets)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = batch_targets.size(0)\n",
    "        total_loss_value += batch_loss.item() * batch_size\n",
    "\n",
    "        batch_predicted = batch_logits.argmax(dim=1)\n",
    "        total_correct += (batch_predicted == batch_targets).sum().item()\n",
    "        total_samples += batch_size\n",
    "\n",
    "    average_loss = total_loss_value / max(1, total_samples)\n",
    "    average_accuracy = total_correct / max(1, total_samples)\n",
    "    return average_loss, average_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running single validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def run_one_epoch_no_grad(\n",
    "    model: nn.Module,\n",
    "    val_dataloader: DataLoader,\n",
    "    loss_function: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "\n",
    "    total_loss_value = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch_images, batch_targets in val_dataloader:\n",
    "        batch_images = batch_images.to(device, non_blocking=True)\n",
    "        batch_targets = batch_targets.to(device, non_blocking=True).long()\n",
    "\n",
    "        batch_logits = model(batch_images)\n",
    "        if isinstance(batch_logits, (tuple, list)):\n",
    "            batch_logits = batch_logits[0]\n",
    "\n",
    "        batch_loss = loss_function(batch_logits, batch_targets)\n",
    "\n",
    "        batch_size = batch_targets.size(0)\n",
    "        total_loss_value += batch_loss.item() * batch_size\n",
    "\n",
    "        batch_predicted = batch_logits.argmax(dim=1)\n",
    "        total_correct += (batch_predicted == batch_targets).sum().item()\n",
    "        total_samples += batch_size\n",
    "\n",
    "    average_loss = total_loss_value / max(1, total_samples)\n",
    "    average_accuracy = total_correct / max(1, total_samples)\n",
    "    return average_loss, average_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop with early stopping that returns the model that acheived the best results instead of the latest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_early_stopping(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    val_dataloader: DataLoader,\n",
    "    test_dataloader: DataLoader,\n",
    "    loss_function: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    optimizer_factory: Callable[[nn.Module], torch.optim.Optimizer],\n",
    "    device: torch.device,\n",
    "    max_epochs: int = MAX_EPOCHS,\n",
    "    improvement_delta: float = IMPROVEMENT_DELTA,\n",
    "    patience_epochs: int = PATIENCE_EPOCHS\n",
    ") -> nn.Module:\n",
    "    epoch_loss: list[float] = list()\n",
    "    epoch_acc: list[float] = list()\n",
    "    epoch_val_loss: list[float] = list()\n",
    "    epoch_val_acc: list[float] = list()\n",
    "    epoch_test_loss: list[float] = list()\n",
    "    epoch_test_acc: list[float] = list()\n",
    "    optimizer = optimizer_factory(model)\n",
    "    early_stopper = EarlyStopper(patience_epochs=patience_epochs, min_delta=improvement_delta)\n",
    "    for epoch_index in range(1, max_epochs + 1):\n",
    "        start = time.time()\n",
    "        train_loss, train_accuracy = run_one_epoch_train(\n",
    "            model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            loss_function=loss_function,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "        )\n",
    "        val_loss, val_accuracy = run_one_epoch_no_grad(\n",
    "            model=model,\n",
    "            val_dataloader=val_dataloader,\n",
    "            loss_function=loss_function,\n",
    "            device=device,\n",
    "        )\n",
    "        test_loss, test_accuracy = run_one_epoch_no_grad(\n",
    "            model=model,\n",
    "            val_dataloader=test_dataloader,\n",
    "            loss_function=loss_function,\n",
    "            device=device,\n",
    "        )\n",
    "        epoch_loss.append(train_loss)\n",
    "        epoch_acc.append(train_accuracy)\n",
    "        epoch_val_loss.append(val_loss)\n",
    "        epoch_val_acc.append(val_accuracy)\n",
    "        epoch_test_loss.append(test_loss)\n",
    "        epoch_test_acc.append(test_accuracy)\n",
    "        print(\n",
    "            f\"Epoch {epoch_index:03d} | \"\n",
    "            f\"train_loss={train_loss:.6f}, train_acc={train_accuracy:.4f} | \"\n",
    "            f\"val_loss={val_loss:.6f}, val_acc={val_accuracy:.4f} | Epoch time: {time.time() - start:.2f} seconds\"\n",
    "        )\n",
    "\n",
    "        should_stop, improved = early_stopper.step(current_value=val_loss, model=model)\n",
    "        if not improved:\n",
    "            print(\n",
    "                f\"No improvement in val_loss for {early_stopper.epochs_without_improvement} \"\n",
    "                f\"out of {patience_epochs} allowed epochs.\"\n",
    "            )\n",
    "        if should_stop:\n",
    "            print(\n",
    "                f\"Early stopping: no val_loss improvement >= {improvement_delta} \"\n",
    "                f\"for {patience_epochs} epochs.\"\n",
    "            )\n",
    "            break\n",
    "        print(f\"\")\n",
    "    model.load_state_dict(early_stopper.best_state_dict)\n",
    "    print(\"Loaded best model weights (by validation loss).\")\n",
    "    model.eval()\n",
    "    return model, epoch_loss, epoch_acc, epoch_val_loss, epoch_val_acc, epoch_test_loss, epoch_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    loss_function: torch.nn.Module,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True).long()\n",
    "\n",
    "            logits = model(images)\n",
    "            if isinstance(logits, (tuple, list)):  # in case model returns extra outputs\n",
    "                logits = logits[0]\n",
    "\n",
    "            loss = loss_function(logits, targets)\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == targets).sum().item()\n",
    "            total_samples += images.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing classifier head with a different classifier due to different categories and nubmer of categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_last_linear_layer(model: nn.Module, num_classes: int) -> nn.Module:\n",
    "    last_linear_name = None\n",
    "    last_linear_module = None\n",
    "\n",
    "    for module_name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            last_linear_name = module_name\n",
    "            last_linear_module = module\n",
    "\n",
    "    if last_linear_module is None:\n",
    "        raise RuntimeError(\"No nn.Linear layer found to replace.\")\n",
    "\n",
    "    new_linear_layer = nn.Linear(last_linear_module.in_features, num_classes)\n",
    "\n",
    "    # set by walking to the parent module\n",
    "    parent = model\n",
    "    name_parts = last_linear_name.split(\".\")\n",
    "    for part in name_parts[:-1]:\n",
    "        parent = getattr(parent, part)\n",
    "    setattr(parent, name_parts[-1], new_linear_layer)\n",
    "\n",
    "    print(f\"Replaced: {last_linear_name} -> Linear({last_linear_module.in_features}, {num_classes})\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare fresh yolo5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fresh_yolo5_model(\n",
    "        num_classes: int,\n",
    "        device: torch.device) -> nn.Module:\n",
    "    yolo_model = torch.hub.load(\n",
    "    \"ultralytics/yolov5\",\n",
    "    \"custom\",\n",
    "    path=f\"{YOLOV5_MODEL}-cls.pt\",   # classification checkpoint\n",
    "    autoshape=False,        # important for training\n",
    "    verbose=False\n",
    "    )\n",
    "    yolo_model = replace_last_linear_layer(yolo_model, num_classes)\n",
    "    yolo_model = yolo_model.to(device)\n",
    "    yolo_model.train()\n",
    "    return yolo_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare fresh vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fresh_vgg19_model(\n",
    "        num_classes: int,\n",
    "        device: torch.device,\n",
    "        weight_location: str = FRESH_LOCAL_VGG_WEIGHTS\n",
    "        ) -> nn.Module:\n",
    "    ckpt_path = Path(weight_location)\n",
    "    ckpt_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Build architecture (must match the saved state_dict)\n",
    "    model = models.vgg19(weights=None)\n",
    "    model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, num_classes)\n",
    "\n",
    "\n",
    "    # Load if exists, otherwise \"download\" pretrained VGG19 and save\n",
    "    if ckpt_path.exists():\n",
    "        state = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "        model.load_state_dict(state)\n",
    "    else:\n",
    "        base = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)  # downloads if needed\n",
    "        base.classifier[-1] = nn.Linear(base.classifier[-1].in_features, num_classes)\n",
    "        model.load_state_dict(base.state_dict())\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "    \n",
    "    # Freeze ALL parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in model.features[28:].parameters(): \n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Unfreeze ONLY the new last layer\n",
    "    for param in model.classifier[-1].parameters():\n",
    "        param.requires_grad = True\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factory is used since it cannot be used before the model is properly setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo5_optimizer_factory(model):\n",
    "    params = [p for p in model.parameters() if p.requires_grad] # Only trainable parameters\n",
    "    return torch.optim.AdamW(params, lr=3e-4, weight_decay=1e-2)\n",
    "\n",
    "def vgg19_optimizer_factory(model):\n",
    "    params = [p for p in model.parameters() if p.requires_grad] # Only trainable parameters\n",
    "    return torch.optim.SGD(params, lr=1e-3, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_info: list[tuple] = list()\n",
    "for seed in DATA_SPLIT_SEED_LIST:\n",
    "    train_dataset, val_dataset, test_dataset = create_dataset_splits(\n",
    "        full_dataset, \n",
    "        random_seed=seed, \n",
    "        transform_for_train=train_transform, \n",
    "        transform_for_val_test=val_test_transform\n",
    "        )\n",
    "    \n",
    "    train_dataloader, val_dataloader, test_dataloader = create_dataloaders(train_dataset, val_dataset, test_dataset)\n",
    "    # Creating a new model each time.\n",
    "    #\n",
    "    models_to_train = [('VGG19', get_fresh_vgg19_model, vgg19_optimizer_factory), ('Yolo5', get_fresh_yolo5_model, yolo5_optimizer_factory)]\n",
    "    for model_name, model_factory, optimizer_factory in models_to_train:\n",
    "        print(f\"\\n--- Training {model_name} with data seed {seed} ---\")\n",
    "        classifier_model, epoch_loss, epoch_acc, epoch_val_loss, epoch_val_acc, epoch_test_loss, epoch_test_acc = train_with_early_stopping(\n",
    "            model=model_factory(num_classes=num_classes, device=device),\n",
    "            train_dataloader=train_dataloader,\n",
    "            val_dataloader=val_dataloader,\n",
    "            test_dataloader=test_dataloader,\n",
    "            loss_function=loss_function,\n",
    "            optimizer_factory=optimizer_factory,\n",
    "            device=device,\n",
    "            max_epochs=MAX_EPOCHS,\n",
    "        )\n",
    "        test_loss, test_accuracy = evaluate_model(\n",
    "            model=classifier_model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_function=loss_function,\n",
    "            device=device\n",
    "        )\n",
    "        run_data = (model_name, seed, epoch_loss, epoch_acc, epoch_val_loss, epoch_val_acc, epoch_test_loss, epoch_test_acc, test_loss, test_accuracy)\n",
    "        run_info.append(run_data)\n",
    "        with open(f\"{model_name}_run_seed_{seed}.json\", \"w\") as f:\n",
    "            json.dump(run_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exrtacting data from files. Done as a failsafe incase model crashes unexpectdly during a long run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_info: list[tuple] = list()\n",
    "for seed in DATA_SPLIT_SEED_LIST:\n",
    "    for model_name, _, _ in models_to_train:\n",
    "        seed_run_location = f\"{model_name}_run_seed_{seed}.json\"\n",
    "        if os.path.exists(seed_run_location):\n",
    "            with open(seed_run_location) as f:\n",
    "                run_data = json.load(f)\n",
    "                run_info.append(tuple(run_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data: dict = defaultdict(lambda: defaultdict(list))\n",
    "seed_run_data: dict = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for model_name, seed, epoch_loss, epoch_acc, epoch_val_loss, epoch_val_acc, epoch_test_loss, epoch_test_acc, _, _ in run_info:\n",
    "    model_data[model_name]['seed'].append(seed)\n",
    "    model_data[model_name][\"epochs\"].append(len(epoch_loss))\n",
    "    model_data[model_name][\"epoch_loss\"].append(epoch_loss)\n",
    "    model_data[model_name][\"epoch_acc\"].append(epoch_acc)\n",
    "    model_data[model_name][\"epoch_val_loss\"].append(epoch_val_loss)\n",
    "    model_data[model_name][\"epoch_val_acc\"].append(epoch_val_acc)\n",
    "    model_data[model_name][\"epoch_test_loss\"].append(epoch_test_loss)\n",
    "    model_data[model_name][\"epoch_test_acc\"].append(epoch_test_acc)\n",
    "    seed_run_data[seed][model_name] = {\n",
    "        \"epoch_loss\": epoch_loss,\n",
    "        \"epoch_acc\": epoch_acc,\n",
    "        \"epoch_val_loss\": epoch_val_loss,\n",
    "        \"epoch_val_acc\": epoch_val_acc,\n",
    "        \"epoch_test_loss\": epoch_test_loss,\n",
    "        \"epoch_test_acc\": epoch_test_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, data in model_data.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Epochs mean: {np.mean(data['epochs']):.2f}\")\n",
    "    final_train_accs = [accs[-1] for accs in data[\"epoch_acc\"]]\n",
    "    print(f\"  Final training accuracy mean: {np.mean(final_train_accs):.4f}\")\n",
    "    final_val_accs = [accs[-1] for accs in data[\"epoch_val_acc\"]]\n",
    "    print(f\"  Final validation accuracy mean: {np.mean(final_val_accs):.4f}\")\n",
    "    final_train_losses = [losses[-1] for losses in data[\"epoch_loss\"]]\n",
    "    print(f\"  Final training loss mean: {np.mean(final_train_losses):.4f}\")\n",
    "    final_val_losses = [losses[-1] for losses in data[\"epoch_val_loss\"]]\n",
    "    print(f\"  Final validation loss mean: {np.mean(final_val_losses):.4f}\")\n",
    "    print(f\"  Final test loss: {seed_run_data[seed][model_name]['epoch_test_loss'][-1]:.4f}\")\n",
    "    print(f\"  Final test accuracy: {seed_run_data[seed][model_name]['epoch_test_acc'][-1]:.4f}\")\n",
    "    print(\"\")\n",
    "    first_epoch_over_70_train = []\n",
    "    for accs in data[\"epoch_acc\"]:\n",
    "        epoch_idx = next((i+1 for i, acc in enumerate(accs) if acc >= 0.7), len(accs))\n",
    "        first_epoch_over_70_train.append(epoch_idx)\n",
    "    print(f\"  First epoch to reach over 70% acc on training mean: {np.mean(first_epoch_over_70_train):.2f}\")\n",
    "    first_epoch_over_70_val = []\n",
    "    for accs in data[\"epoch_val_acc\"]:\n",
    "        epoch_idx = next((i+1 for i, acc in enumerate(accs) if acc >= 0.7), len(accs))\n",
    "        first_epoch_over_70_val.append(epoch_idx)\n",
    "    print(f\"  First epoch to reach over 70% acc on validation mean: {np.mean(first_epoch_over_70_val):.2f}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphing loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for model_name, data in model_data.items():\n",
    "    max_epochs = max(len(epoch_loss) for epoch_loss in data[\"epoch_loss\"])\n",
    "    epochs = range(1, max_epochs + 1)\n",
    "    seed_index = 0\n",
    "    for (epoch_loss, epoch_val_loss, epoch_test_loss) in zip(data[\"epoch_loss\"], data[\"epoch_val_loss\"], data[\"epoch_test_loss\"]):\n",
    "        plt.plot(epochs[:len(epoch_loss)], epoch_loss, label=f\"{model_name} loss_{data['seed'][seed_index]}\")\n",
    "        plt.plot(epochs[:len(epoch_val_loss)], epoch_val_loss, label=f\"{model_name} val loss_{data['seed'][seed_index]}\")\n",
    "        plt.plot(epochs[:len(epoch_test_loss)], epoch_test_loss, label=f\"{model_name} test loss_{data['seed'][seed_index]}\")\n",
    "        seed_index += 1\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"CE Loss\")\n",
    "    plt.title(f\"{model_name} Loss /w seeds vs Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for model_name, data in model_data.items():\n",
    "    max_epochs = max(len(epoch_acc) for epoch_acc in data[\"epoch_acc\"])\n",
    "    epochs = range(1, max_epochs + 1)\n",
    "    seed_index = 0\n",
    "    for (epoch_acc, epoch_val_acc, epoch_test_acc) in zip(data[\"epoch_acc\"], data[\"epoch_val_acc\"], data[\"epoch_test_acc\"]):\n",
    "        plt.plot(epochs[:len(epoch_acc)], epoch_acc, label=f\"{model_name} acc_{data['seed'][seed_index]}\")\n",
    "        plt.plot(epochs[:len(epoch_val_acc)], epoch_val_acc, label=f\"{model_name} val acc_{data['seed'][seed_index]}\")\n",
    "        plt.plot(epochs[:len(epoch_test_acc)], epoch_test_acc, label=f\"{model_name} test acc_{data['seed'][seed_index]}\")\n",
    "        seed_index += 1\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"{model_name} Accuracy /w seeds vs Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphin data per seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for curr_seed in seed_run_data.keys():\n",
    "    plt.figure()\n",
    "    for model_name, run_data in seed_run_data[curr_seed].items():\n",
    "        epoch_loss = run_data['epoch_loss']\n",
    "        epoch_val_loss = run_data['epoch_val_loss']\n",
    "        epoch_test_loss = run_data['epoch_test_loss']\n",
    "        epochs = range(1, len(epoch_loss) + 1)\n",
    "        plt.plot(epochs, epoch_loss, label=f\"{model_name} loss\")\n",
    "        plt.plot(epochs, epoch_val_loss, label=f\"{model_name} val loss\")\n",
    "        plt.plot(epochs, epoch_test_loss, label=f\"{model_name} test loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"CE Loss\")\n",
    "        plt.title(f\"Model: {model_name} Seed {curr_seed} Loss vs Epochs\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for curr_seed in seed_run_data.keys():\n",
    "    plt.figure()\n",
    "    for model_name, run_data in seed_run_data[curr_seed].items():\n",
    "        epoch_test_loss = run_data['epoch_test_loss']\n",
    "        epochs = range(1, len(epoch_loss) + 1)\n",
    "        plt.plot(epochs, epoch_test_loss, label=f\"{model_name} test loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"CE Loss\")\n",
    "        plt.title(f\"Yolo5 and VGG19, Seed {curr_seed} Test loss vs Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy & loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds: list[int] = list()\n",
    "test_acc_list: list[float] = list()\n",
    "test_loss_list: list[float] = list()\n",
    "for model_name, seed, _, _, _, _, _, _, test_loss, test_accuracy in run_info:\n",
    "    seeds.append(f\"{model_name}_{seed}\")\n",
    "    test_acc_list.append(test_accuracy)\n",
    "    test_loss_list.append(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "bars = plt.bar(seeds, test_loss_list, color=\"skyblue\")\n",
    "\n",
    "plt.xlabel(\"Model & Data Seed\")\n",
    "plt.ylabel(\"Test Loss\")\n",
    "plt.title(\"Test Loss per Seed\")\n",
    "plt.grid(True, axis=\"y\")\n",
    "\n",
    "# Add values on top of bars\n",
    "for bar, loss in zip(bars, test_loss_list):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height(),\n",
    "        f\"{loss:.3f}\",\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "bars = plt.bar(seeds, test_acc_list, color=\"skyblue\")\n",
    "\n",
    "plt.xlabel(\"Model & Data Seed\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Test Accuracy per Seed\")\n",
    "plt.grid(True, axis=\"y\")\n",
    "\n",
    "# Add values on top of bars\n",
    "for bar, acc in zip(bars, test_acc_list):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height(),\n",
    "        f\"{acc:.3f}\",\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final accuracies and losses per model and seed:')\n",
    "print('Accuracy:')\n",
    "for index in range(len(seeds)):\n",
    "    print(f\"{seeds[index]}: {test_acc_list[index]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
